{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preparing_features_labels.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNk+Ymb8J9Dfsp1jvFGXsis",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/time_series_deeplearning.ai/blob/main/week2/preparing_features_labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q67aJ6nxKzE_",
        "outputId": "f3f1e049-2a35-411c-caac-4787673c72ae"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_kvl2BeLLh2"
      },
      "source": [
        "1. Creating a range using tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zUVEGM3K_RW",
        "outputId": "c2a57f8a-372b-4db5-f3de-b747b783b289"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "for val in dataset:\r\n",
        "    print(val.numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaZrLeaQLPu2"
      },
      "source": [
        "2. Creating a window of 5 from the dataset shifted by 1 after each window:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUOo3sfVLHp4",
        "outputId": "46bef48c-c325-44e0-81cc-eefdc6d3d46f"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "window = dataset.window(5, shift=1)\r\n",
        "for i, w in enumerate(window):\r\n",
        "    print(\"#window:\",i,\":\",end=\" \")\r\n",
        "    for val in w:\r\n",
        "        print(val.numpy(),end=\" \")\r\n",
        "    print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#window: 0 : 0 1 2 3 4 \n",
            "#window: 1 : 1 2 3 4 5 \n",
            "#window: 2 : 2 3 4 5 6 \n",
            "#window: 3 : 3 4 5 6 7 \n",
            "#window: 4 : 4 5 6 7 8 \n",
            "#window: 5 : 5 6 7 8 9 \n",
            "#window: 6 : 6 7 8 9 \n",
            "#window: 7 : 7 8 9 \n",
            "#window: 8 : 8 9 \n",
            "#window: 9 : 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j2XcU9OMQlv"
      },
      "source": [
        "To just get chuncks of exactly 5 sets, we will use drop remainder to True:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPX4jDizLtZ5",
        "outputId": "4be4d71f-067b-4b73-b83e-78a340baab26"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "window = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "for i, w in enumerate(window):\r\n",
        "    print(\"#window:\",i,\":\",end=\" \")\r\n",
        "    for val in w:\r\n",
        "        print(val.numpy(),end=\" \")\r\n",
        "    print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#window: 0 : 0 1 2 3 4 \n",
            "#window: 1 : 1 2 3 4 5 \n",
            "#window: 2 : 2 3 4 5 6 \n",
            "#window: 3 : 3 4 5 6 7 \n",
            "#window: 4 : 4 5 6 7 8 \n",
            "#window: 5 : 5 6 7 8 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLJTxsS0MZia"
      },
      "source": [
        "3. Now converting the data to numpy format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qsYlns2MZ4I",
        "outputId": "e3a0358e-3181-483c-d484-61dbf75278ad"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda x: x.batch(5))\r\n",
        "for window in dataset:\r\n",
        "    print(window.numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpsygoRKNHJ3"
      },
      "source": [
        "4. Splitting the dataset into features and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RglRVOJfNG88",
        "outputId": "3e89ddaa-ceb3-4d2c-ada0-1cee35e7c995"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda x: x.batch(5))\r\n",
        "dataset = dataset.map(lambda x: (x[:-1], x[-1:]))\r\n",
        "print(\"features\\tlabel\")\r\n",
        "for x,y in dataset:\r\n",
        "    print(x.numpy(),\"\\t\",y.numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features\tlabel\n",
            "[0 1 2 3] \t [4]\n",
            "[1 2 3 4] \t [5]\n",
            "[2 3 4 5] \t [6]\n",
            "[3 4 5 6] \t [7]\n",
            "[4 5 6 7] \t [8]\n",
            "[5 6 7 8] \t [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjtiJWYwNnNV"
      },
      "source": [
        "5. Shuffling the data to avoid sequence biases during training:\r\n",
        "\r\n",
        "\r\n",
        "**Sequence bias**:\r\n",
        "\r\n",
        "Sequence bias is when the order of things can impact the selection of things. For example, if I were to ask you your favorite TV show, and listed \"Game of Thrones\", \"Killing Eve\", \"Travellers\" and \"Doctor Who\" in that order, you're probably more likely to select 'Game of Thrones' as you are familiar with it, and it's the first thing you see. Even if it is equal to the other TV shows. So, when training data in a dataset, we don't want the sequence to impact the training in a similar way, so it's good to shuffle them up. \r\n",
        "\r\n",
        "\r\n",
        "**What is shuffle buffer ?**\r\n",
        "\r\n",
        "Using a shuffle buffer speeds things up a bit. So for example, if you have 100,000 items in your dataset, but you set the buffer to a thousand. It will just fill the buffer with the first thousand elements, pick one of them at random. And then it will replace that with the 1,000 and first element before randomly picking again, and so on. This way with super large datasets, the random element choosing can choose from a smaller number which effectively speeds things up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3CE8bP7Nd__",
        "outputId": "f0c19b52-16e4-4e76-9843-58d94aa29061"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda x: x.batch(5))\r\n",
        "dataset = dataset.map(lambda x: (x[:-1], x[-1:]))\r\n",
        "dataset = dataset.shuffle(buffer_size=10)\r\n",
        "print(\"features\\tlabel\")\r\n",
        "for x,y in dataset:\r\n",
        "    print(x.numpy(),\"\\t\",y.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features\tlabel\n",
            "[2 3 4 5] \t [6]\n",
            "[4 5 6 7] \t [8]\n",
            "[1 2 3 4] \t [5]\n",
            "[0 1 2 3] \t [4]\n",
            "[5 6 7 8] \t [9]\n",
            "[3 4 5 6] \t [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdZbNGakN5fO"
      },
      "source": [
        "6. Batching the data: this will allow faster training, training the model with $n$ features and label at a time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoEJRZbKOGEb",
        "outputId": "d9f9fab5-d526-49e9-d805-efacfa6c25d5"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda x: x.batch(5))\r\n",
        "dataset = dataset.map(lambda x: (x[:-1], x[-1:]))\r\n",
        "dataset = dataset.shuffle(buffer_size=10)\r\n",
        "dataset = dataset.batch(2).prefetch(1)\r\n",
        "\r\n",
        "for x,y in dataset:\r\n",
        "    print(x.numpy(),y.numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 4 5 6]\n",
            " [1 2 3 4]] [[7]\n",
            " [5]]\n",
            "[[4 5 6 7]\n",
            " [2 3 4 5]] [[8]\n",
            " [6]]\n",
            "[[5 6 7 8]\n",
            " [0 1 2 3]] [[9]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}